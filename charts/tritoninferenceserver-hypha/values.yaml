replicaCount: 1
image:
  imageName: nvcr.io/nvidia/tritonserver:23.08-py3
  pullPolicy: IfNotPresent
  # modelRepositoryPath: s3://imjoy-s3.pasteur.fr:80/model-repository
  modelSnapshots: /model-snapshots
  modelRepository: /model-repository
  modelStore: /model-repository
  numGpus: 0
  s3Endpoint: ""
  s3Bucket: ""
  env:
  - name: TF_FORCE_GPU_ALLOW_GROWTH
    value: "true"

cache:
  ephemeral:
    volumeClaimTemplate:
      spec:
        accessModes: ["ReadWriteOnce"]
        # storageClassName: "standard"
        resources:
          requests:
            storage: 8Gi

ingress:
  enabled: false
  className: nginx
  path: /
  # Used to create an Ingress record.
  hosts:
  - chart-example.local
  name: tritoninferenceserver
  type: ClusterIP
  port: 8000
  annotations: {}

resources:
  requests:
    nvidia.com/gpu: 0
    memory: "2Gi"
    cpu: "1"
  limits:
    nvidia.com/gpu: 0
    memory: "3Gi"
    cpu: "1"

service:
  port: 8000

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  gpuUtilization: 50
#   gpuMemoryUtilization: 50


nodeSelector: {}
podLabels: {}

readinessProbe:
  httpGet:
    path: /v2/health/ready
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 2
  successThreshold: 1
  failureThreshold: 3

livenessProbe:
  httpGet:
    path: /v2/health/live
    port: 8000
  initialDelaySeconds: 1800
  periodSeconds: 5
  timeoutSeconds: 2
  successThreshold: 1
  failureThreshold: 3
